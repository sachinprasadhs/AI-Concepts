{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sravanneeli/attention-variations-ipynb?scriptVersionId=174041742\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"73aaea09","metadata":{"papermill":{"duration":0.00895,"end_time":"2024-04-26T00:33:10.518387","exception":false,"start_time":"2024-04-26T00:33:10.509437","status":"completed"},"tags":[]},"source":["# What is Einsum ?\n","\n","* Let's say we want to multiply two matrices `A` and `B` followed by calculating the sum of each column resulting in a vector `C`. Using Einstein summation notation, we can write this as\n","\n","$$c_{j} = \\sum_{i} \\sum_{j} A_{ik}B_{kj} = A_{ik}B_{kj}$$\n"]},{"cell_type":"code","execution_count":1,"id":"b72a08d1","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-26T00:33:10.536383Z","iopub.status.busy":"2024-04-26T00:33:10.535647Z","iopub.status.idle":"2024-04-26T00:33:12.919942Z","shell.execute_reply":"2024-04-26T00:33:12.918899Z"},"papermill":{"duration":2.395757,"end_time":"2024-04-26T00:33:12.922332","exception":false,"start_time":"2024-04-26T00:33:10.526575","status":"completed"},"tags":[]},"outputs":[],"source":["import jax\n","import jax.numpy as jnp\n","import optax"]},{"cell_type":"code","execution_count":2,"id":"f75a8aee","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:12.939817Z","iopub.status.busy":"2024-04-26T00:33:12.939367Z","iopub.status.idle":"2024-04-26T00:33:13.383514Z","shell.execute_reply":"2024-04-26T00:33:13.382651Z"},"papermill":{"duration":0.455203,"end_time":"2024-04-26T00:33:13.385975","exception":false,"start_time":"2024-04-26T00:33:12.930772","status":"completed"},"tags":[]},"outputs":[],"source":["a = jnp.arange(6).reshape((2, 3))"]},{"cell_type":"markdown","id":"5c1516ac","metadata":{"papermill":{"duration":0.007407,"end_time":"2024-04-26T00:33:13.401371","exception":false,"start_time":"2024-04-26T00:33:13.393964","status":"completed"},"tags":[]},"source":["# Transpose"]},{"cell_type":"code","execution_count":3,"id":"a778e250","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:13.418659Z","iopub.status.busy":"2024-04-26T00:33:13.418003Z","iopub.status.idle":"2024-04-26T00:33:13.453822Z","shell.execute_reply":"2024-04-26T00:33:13.452858Z"},"papermill":{"duration":0.047083,"end_time":"2024-04-26T00:33:13.45607","exception":false,"start_time":"2024-04-26T00:33:13.408987","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([[0, 3],\n","       [1, 4],\n","       [2, 5]], dtype=int32)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["jnp.einsum(\"ij->ji\", a) # basically the notation is saying in abstract way to change each element from i,j position to j,i -> this is what expected in transpose"]},{"cell_type":"markdown","id":"e6c0a4d9","metadata":{"papermill":{"duration":0.007535,"end_time":"2024-04-26T00:33:13.471577","exception":false,"start_time":"2024-04-26T00:33:13.464042","status":"completed"},"tags":[]},"source":["# Matrix Sum"]},{"cell_type":"code","execution_count":4,"id":"ca9a2278","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:13.489429Z","iopub.status.busy":"2024-04-26T00:33:13.489094Z","iopub.status.idle":"2024-04-26T00:33:13.528489Z","shell.execute_reply":"2024-04-26T00:33:13.527666Z"},"papermill":{"duration":0.050288,"end_time":"2024-04-26T00:33:13.530455","exception":false,"start_time":"2024-04-26T00:33:13.480167","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array(15, dtype=int32)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["jnp.einsum(\"ij->\", a) # matrix sum is a single scalar output so there is no notation after `->` which means collapse all columns and rows"]},{"cell_type":"markdown","id":"d635bed8","metadata":{"papermill":{"duration":0.007896,"end_time":"2024-04-26T00:33:13.546476","exception":false,"start_time":"2024-04-26T00:33:13.53858","status":"completed"},"tags":[]},"source":["# Column Sum"]},{"cell_type":"code","execution_count":5,"id":"5da28a5a","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:13.564031Z","iopub.status.busy":"2024-04-26T00:33:13.563272Z","iopub.status.idle":"2024-04-26T00:33:13.59038Z","shell.execute_reply":"2024-04-26T00:33:13.589415Z"},"papermill":{"duration":0.038149,"end_time":"2024-04-26T00:33:13.592565","exception":false,"start_time":"2024-04-26T00:33:13.554416","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([3, 5, 7], dtype=int32)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["jnp.einsum(\"ij->j\", a) # matrix sum column wise so the output has only how many dimensions in the column so rows are collapsed."]},{"cell_type":"markdown","id":"fc0c8c72","metadata":{"papermill":{"duration":0.008099,"end_time":"2024-04-26T00:33:13.608922","exception":false,"start_time":"2024-04-26T00:33:13.600823","status":"completed"},"tags":[]},"source":["# Row Sum"]},{"cell_type":"code","execution_count":6,"id":"199abb90","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:13.628627Z","iopub.status.busy":"2024-04-26T00:33:13.628048Z","iopub.status.idle":"2024-04-26T00:33:13.653968Z","shell.execute_reply":"2024-04-26T00:33:13.652989Z"},"papermill":{"duration":0.037725,"end_time":"2024-04-26T00:33:13.656238","exception":false,"start_time":"2024-04-26T00:33:13.618513","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([ 3, 12], dtype=int32)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["jnp.einsum(\"ij->i\", a)"]},{"cell_type":"markdown","id":"7191e924","metadata":{"papermill":{"duration":0.007936,"end_time":"2024-04-26T00:33:13.672537","exception":false,"start_time":"2024-04-26T00:33:13.664601","status":"completed"},"tags":[]},"source":["# Matrix-Vector Multiplication\n","\n","\n"]},{"cell_type":"code","execution_count":7,"id":"a48e7b31","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:13.690654Z","iopub.status.busy":"2024-04-26T00:33:13.689982Z","iopub.status.idle":"2024-04-26T00:33:13.73847Z","shell.execute_reply":"2024-04-26T00:33:13.737378Z"},"papermill":{"duration":0.059994,"end_time":"2024-04-26T00:33:13.740639","exception":false,"start_time":"2024-04-26T00:33:13.680645","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([ 5, 14], dtype=int32)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["b = jnp.arange(3) # (3, )\n","jnp.einsum(\"ij,j->i\", a, b) # same as jnp.dot(a, b)"]},{"cell_type":"markdown","id":"66b9dbfc","metadata":{"papermill":{"duration":0.007979,"end_time":"2024-04-26T00:33:13.756992","exception":false,"start_time":"2024-04-26T00:33:13.749013","status":"completed"},"tags":[]},"source":["# Matrix-Matrix Multiplication"]},{"cell_type":"code","execution_count":8,"id":"a7962393","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:13.774411Z","iopub.status.busy":"2024-04-26T00:33:13.774065Z","iopub.status.idle":"2024-04-26T00:33:13.840086Z","shell.execute_reply":"2024-04-26T00:33:13.838975Z"},"papermill":{"duration":0.077134,"end_time":"2024-04-26T00:33:13.842207","exception":false,"start_time":"2024-04-26T00:33:13.765073","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([[ 25,  28,  31,  34,  37],\n","       [ 70,  82,  94, 106, 118]], dtype=int32)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["a = jnp.arange(6).reshape(2, 3)\n","b = jnp.arange(15).reshape(3, 5)\n","jnp.einsum('ik,kj->ij', a, b)"]},{"cell_type":"code","execution_count":9,"id":"dee6d122","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:13.860427Z","iopub.status.busy":"2024-04-26T00:33:13.860082Z","iopub.status.idle":"2024-04-26T00:33:13.895126Z","shell.execute_reply":"2024-04-26T00:33:13.89407Z"},"papermill":{"duration":0.046428,"end_time":"2024-04-26T00:33:13.897216","exception":false,"start_time":"2024-04-26T00:33:13.850788","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([ 95, 110, 125, 140, 155], dtype=int32)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["jnp.einsum('ik,kj->j', a, b) # matrix multiplication plus columns wise sum"]},{"cell_type":"code","execution_count":10,"id":"2e116511","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:13.915898Z","iopub.status.busy":"2024-04-26T00:33:13.915553Z","iopub.status.idle":"2024-04-26T00:33:13.949099Z","shell.execute_reply":"2024-04-26T00:33:13.948097Z"},"papermill":{"duration":0.045377,"end_time":"2024-04-26T00:33:13.951198","exception":false,"start_time":"2024-04-26T00:33:13.905821","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([155, 470], dtype=int32)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["jnp.einsum('ik,kj->i', a, b) # matrix multiplication plus row wise sum"]},{"cell_type":"markdown","id":"b95748b5","metadata":{"papermill":{"duration":0.008275,"end_time":"2024-04-26T00:33:13.968268","exception":false,"start_time":"2024-04-26T00:33:13.959993","status":"completed"},"tags":[]},"source":["# Dot Product"]},{"cell_type":"code","execution_count":11,"id":"3285bf22","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:13.986875Z","iopub.status.busy":"2024-04-26T00:33:13.986492Z","iopub.status.idle":"2024-04-26T00:33:14.028473Z","shell.execute_reply":"2024-04-26T00:33:14.02744Z"},"papermill":{"duration":0.053669,"end_time":"2024-04-26T00:33:14.030428","exception":false,"start_time":"2024-04-26T00:33:13.976759","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array(14, dtype=int32)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["a = jnp.arange(3)\n","b = jnp.arange(3,6)\n","jnp.einsum('i,i->', a, b) # notation is basically i is index of a matrix and the i index in b multiplied index wise"]},{"cell_type":"markdown","id":"8499771b","metadata":{"papermill":{"duration":0.008404,"end_time":"2024-04-26T00:33:14.047663","exception":false,"start_time":"2024-04-26T00:33:14.039259","status":"completed"},"tags":[]},"source":["# Element Wise Multiplication of Two Matrices and the summation"]},{"cell_type":"code","execution_count":12,"id":"b413c8b2","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:14.067564Z","iopub.status.busy":"2024-04-26T00:33:14.066569Z","iopub.status.idle":"2024-04-26T00:33:14.110135Z","shell.execute_reply":"2024-04-26T00:33:14.109087Z"},"papermill":{"duration":0.055548,"end_time":"2024-04-26T00:33:14.112379","exception":false,"start_time":"2024-04-26T00:33:14.056831","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([[ 0,  7, 16],\n","       [27, 40, 55]], dtype=int32)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["a = jnp.arange(6).reshape(2, 3)\n","b = jnp.arange(6,12).reshape(2, 3)\n","jnp.einsum('ij,ij->ij', a, b)"]},{"cell_type":"code","execution_count":13,"id":"cbf7bd7c","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:14.13168Z","iopub.status.busy":"2024-04-26T00:33:14.130903Z","iopub.status.idle":"2024-04-26T00:33:14.158729Z","shell.execute_reply":"2024-04-26T00:33:14.15757Z"},"papermill":{"duration":0.039672,"end_time":"2024-04-26T00:33:14.160896","exception":false,"start_time":"2024-04-26T00:33:14.121224","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array(145, dtype=int32)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["jnp.einsum('ij,ij->', a, b)"]},{"cell_type":"markdown","id":"e6fe0808","metadata":{"papermill":{"duration":0.008521,"end_time":"2024-04-26T00:33:14.178938","exception":false,"start_time":"2024-04-26T00:33:14.170417","status":"completed"},"tags":[]},"source":["# Outer Product\n","\n","Given two vectors of size $m \\times 1$ and $n \\times 1$respectively\n","\n","$$ u = \\begin{bmatrix}\n","  u_{1} \\\\\n","  u_{2} \\\\\n","  u_{3} \\\\\n","  u_{4} \\\\\n","\\end{bmatrix}\n","\\,\n","v = \\begin{bmatrix}\n","  v_{1} \\\\\n","  v_{2} \\\\\n","  v_{3} \\\\\n","\\end{bmatrix}$$\n","$$$$\n","$$ u \\otimes  v = uv^{T} = \\begin{bmatrix}\n","  u_{1}v_{1} & u_{1}v_{2} & u_{1}v_{3}\\\\\n","  u_{2}v_{1} & u_{2}v_{2} & u_{2}v_{3}\\\\\n","  u_{3}v_{1} & u_{3}v_{2} & u_{3}v_{3}\\\\\n","  u_{4}v_{1} & u_{4}v_{2} & u_{4}v_{3}\\\\\n","\\end{bmatrix}$$"]},{"cell_type":"code","execution_count":14,"id":"8aa7f6d9","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:14.197691Z","iopub.status.busy":"2024-04-26T00:33:14.197378Z","iopub.status.idle":"2024-04-26T00:33:14.2395Z","shell.execute_reply":"2024-04-26T00:33:14.238441Z"},"papermill":{"duration":0.054136,"end_time":"2024-04-26T00:33:14.241791","exception":false,"start_time":"2024-04-26T00:33:14.187655","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([[ 0,  0,  0,  0],\n","       [ 3,  4,  5,  6],\n","       [ 6,  8, 10, 12]], dtype=int32)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["a = jnp.arange(3)\n","b = jnp.arange(3,7)\n","jnp.einsum('i,j->ij', a, b)"]},{"cell_type":"markdown","id":"49d07368","metadata":{"papermill":{"duration":0.00869,"end_time":"2024-04-26T00:33:14.259606","exception":false,"start_time":"2024-04-26T00:33:14.250916","status":"completed"},"tags":[]},"source":["# Dot-Product Attention\n","\n","$$ Attention(q, K, V) = softmax(\\dfrac {q \\cdot K^{T}}{\\sqrt d_{k}})V$$"]},{"cell_type":"code","execution_count":15,"id":"c2b8e3e4","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:14.279573Z","iopub.status.busy":"2024-04-26T00:33:14.278505Z","iopub.status.idle":"2024-04-26T00:33:14.284368Z","shell.execute_reply":"2024-04-26T00:33:14.283676Z"},"papermill":{"duration":0.017681,"end_time":"2024-04-26T00:33:14.286155","exception":false,"start_time":"2024-04-26T00:33:14.268474","status":"completed"},"tags":[]},"outputs":[],"source":["def dot_product_attention(q, K, V):\n","    \"\"\" \n","    Dot−Product Attention on one query.\n","    Args :\n","        q : a vector with shape [k]\n","        K: a matrix with shape [m, k]\n","        V: a ma trix with shape [m, v]\n","    Returns :\n","        y : a vector with shape [v]\n","    \"\"\"\n","    \n","    logits = jnp.einsum(\"k,mk->m\", q, K)\n","    weights = jax.nn.softmax(logits)\n","    return jnp.einsum(\"m,mv->v\", weights, V)\n","    "]},{"cell_type":"code","execution_count":16,"id":"b1134bf8","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:14.305115Z","iopub.status.busy":"2024-04-26T00:33:14.304606Z","iopub.status.idle":"2024-04-26T00:33:14.344035Z","shell.execute_reply":"2024-04-26T00:33:14.343177Z"},"papermill":{"duration":0.051291,"end_time":"2024-04-26T00:33:14.346275","exception":false,"start_time":"2024-04-26T00:33:14.294984","status":"completed"},"tags":[]},"outputs":[],"source":["key = jax.random.PRNGKey(13)\n","d_model = 512\n","seq_len = 128\n","num_heads = 8\n","batch_size = 32"]},{"cell_type":"code","execution_count":17,"id":"771e5bdb","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:14.366946Z","iopub.status.busy":"2024-04-26T00:33:14.365891Z","iopub.status.idle":"2024-04-26T00:33:14.686425Z","shell.execute_reply":"2024-04-26T00:33:14.685503Z"},"papermill":{"duration":0.333225,"end_time":"2024-04-26T00:33:14.688741","exception":false,"start_time":"2024-04-26T00:33:14.355516","status":"completed"},"tags":[]},"outputs":[],"source":["q = jax.random.uniform(key, shape=(d_model // num_heads,)) # One token with embedding size of 384 projected to a 64 one of head\n","K = jax.random.uniform(key, shape=(seq_len, d_model // num_heads)) # consider a sentence with max of 128 sequence length and each token with 384 dimension projected to a 64 one of head\n","V = jax.random.uniform(key, shape=(seq_len, d_model // num_heads)) # consider a sentence with max of 128 sequence length and each token with 384 dimension projected to a 64 one of head"]},{"cell_type":"code","execution_count":18,"id":"978e9c57","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:14.708923Z","iopub.status.busy":"2024-04-26T00:33:14.708268Z","iopub.status.idle":"2024-04-26T00:33:14.71352Z","shell.execute_reply":"2024-04-26T00:33:14.712592Z"},"papermill":{"duration":0.017545,"end_time":"2024-04-26T00:33:14.715795","exception":false,"start_time":"2024-04-26T00:33:14.69825","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["q: (64,)\n","K: (128, 64)\n","V: (128, 64)\n"]}],"source":["print(f\"q: {q.shape}\")\n","print(f\"K: {K.shape}\")\n","print(f\"V: {V.shape}\")"]},{"cell_type":"code","execution_count":19,"id":"8bba679c","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:14.734943Z","iopub.status.busy":"2024-04-26T00:33:14.7346Z","iopub.status.idle":"2024-04-26T00:33:14.898671Z","shell.execute_reply":"2024-04-26T00:33:14.897415Z"},"papermill":{"duration":0.176001,"end_time":"2024-04-26T00:33:14.90083","exception":false,"start_time":"2024-04-26T00:33:14.724829","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(64,)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["attention_scores = dot_product_attention(q, K, V)\n","attention_scores.shape"]},{"cell_type":"markdown","id":"4b42f4c6","metadata":{"papermill":{"duration":0.009289,"end_time":"2024-04-26T00:33:14.919422","exception":false,"start_time":"2024-04-26T00:33:14.910133","status":"completed"},"tags":[]},"source":["# Scaled Dot-Product Attention\n","\n","$$ Attention(Q, K, V) = softmax(\\dfrac {Q \\cdot K^{T}}{\\sqrt d_{k}})V$$"]},{"cell_type":"code","execution_count":20,"id":"83bbb990","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:14.939187Z","iopub.status.busy":"2024-04-26T00:33:14.938579Z","iopub.status.idle":"2024-04-26T00:33:14.94415Z","shell.execute_reply":"2024-04-26T00:33:14.942942Z"},"papermill":{"duration":0.017527,"end_time":"2024-04-26T00:33:14.946067","exception":false,"start_time":"2024-04-26T00:33:14.92854","status":"completed"},"tags":[]},"outputs":[],"source":["def scaled_dot_product_attention(Q, K, V):\n","    \"\"\" \n","    Scaled Dot−Product Attention on maximum sequence length of queries.\n","    Args :\n","        Q: a matrix with shape [m, q]\n","        K: a matrix with shape [m, k]\n","        V: a matrix with shape [m, v]\n","    Returns :\n","        y : a vector with shape [m, v]\n","    \"\"\"\n","    \n","    logits = jnp.einsum(\"mq,mk->qk\", Q, K)\n","    weights = jax.nn.softmax(logits)\n","    return jnp.einsum(\"vv,mv->mv\", weights, V)\n","    "]},{"cell_type":"code","execution_count":21,"id":"3fe972ee","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:14.965793Z","iopub.status.busy":"2024-04-26T00:33:14.965439Z","iopub.status.idle":"2024-04-26T00:33:14.971977Z","shell.execute_reply":"2024-04-26T00:33:14.971196Z"},"papermill":{"duration":0.018601,"end_time":"2024-04-26T00:33:14.973666","exception":false,"start_time":"2024-04-26T00:33:14.955065","status":"completed"},"tags":[]},"outputs":[],"source":["Q = jax.random.uniform(key, shape=(seq_len, d_model // num_heads)) # consider a sentence with max of 128 sequence length and each token with 384 dimension projected to a 64 one of head\n","K = jax.random.uniform(key, shape=(seq_len, d_model // num_heads)) # consider a sentence with max of 128 sequence length and each token with 384 dimension projected to a 64 one of head\n","V = jax.random.uniform(key, shape=(seq_len, d_model // num_heads)) # consider a sentence with max of 128 sequence length and each token with 384 dimension projected to a 64 one of head"]},{"cell_type":"code","execution_count":22,"id":"03dbbf16","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:14.992997Z","iopub.status.busy":"2024-04-26T00:33:14.992624Z","iopub.status.idle":"2024-04-26T00:33:15.231087Z","shell.execute_reply":"2024-04-26T00:33:15.230008Z"},"papermill":{"duration":0.250436,"end_time":"2024-04-26T00:33:15.233224","exception":false,"start_time":"2024-04-26T00:33:14.982788","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(128, 64)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["attention_scores = scaled_dot_product_attention(Q, K, V)\n","attention_scores.shape"]},{"cell_type":"code","execution_count":23,"id":"f897201e","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:15.253335Z","iopub.status.busy":"2024-04-26T00:33:15.25302Z","iopub.status.idle":"2024-04-26T00:33:15.259317Z","shell.execute_reply":"2024-04-26T00:33:15.258368Z"},"papermill":{"duration":0.018475,"end_time":"2024-04-26T00:33:15.26119","exception":false,"start_time":"2024-04-26T00:33:15.242715","status":"completed"},"tags":[]},"outputs":[],"source":["def multi_head_attention(\n","    X, M, P_q, P_k, P_v, P_o):\n","    \"\"\"Multi-head Attention on maximum sequence length of queries.\n","    Args:\n","        X: a matrix with shape of [n, d]\n","        M: a matrix with shape of [m, d]\n","        P_q: a tensor with shape of [h, d, k]\n","        P_k: a tensor with shape of [h, d, k]\n","        P_v: a tensor with shape of [h, d, v]\n","        P_o:  a tensor with shape of [h, d, v]\n","    Returns:\n","        y: a tensor with shape of [n, d]\n","    \"\"\"\n","    Q = jnp.einsum(\"nd,hdk->hnk\", X, P_q)\n","    K = jnp.einsum(\"md,hdk->hmk\", M, P_k)\n","    V = jnp.einsum(\"md,hdv->hmv\", M, P_v)\n","    \n","    logits = jnp.einsum(\"hnk,hmk->hnm\", Q, K)\n","    weights = jax.nn.softmax(logits)\n","    O = jnp.einsum(\"hnm,hmv->hnv\", weights, V)\n","    Y = jnp.einsum(\"hnv,hdv->nd\", O, P_o)\n","    \n","    return Y"]},{"cell_type":"code","execution_count":24,"id":"8c65ae8f","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:15.28098Z","iopub.status.busy":"2024-04-26T00:33:15.280628Z","iopub.status.idle":"2024-04-26T00:33:16.288478Z","shell.execute_reply":"2024-04-26T00:33:16.287458Z"},"papermill":{"duration":1.02035,"end_time":"2024-04-26T00:33:16.290792","exception":false,"start_time":"2024-04-26T00:33:15.270442","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(128, 512)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["X = jax.random.uniform(key, shape=(seq_len, d_model)) # Input tensor with seq_len and embedding size \n","M = jax.random.uniform(key, shape=(seq_len, d_model)) \n","\n","# Basically this is the dense layer weights, so when input is passed through dense layer we will get an outputs shape (heads, seql_len, head_size) projection\n","P_q = jax.random.uniform(key, shape=(seq_len, d_model, d_model // num_heads)) # Projection of input tensor embeddings to each head size which is d_model // num_heads\n","P_k = jax.random.uniform(key, shape=(seq_len, d_model, d_model // num_heads))\n","P_v = jax.random.uniform(key, shape=(seq_len, d_model, d_model // num_heads))\n","P_o = jax.random.uniform(key, shape=(seq_len, d_model, d_model // num_heads))\n","\n","attention_scores = multi_head_attention(X, M, P_q, P_k, P_v, P_o)\n","attention_scores.shape"]},{"cell_type":"code","execution_count":25,"id":"cef84ff8","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:16.311567Z","iopub.status.busy":"2024-04-26T00:33:16.310778Z","iopub.status.idle":"2024-04-26T00:33:16.317147Z","shell.execute_reply":"2024-04-26T00:33:16.316308Z"},"papermill":{"duration":0.018979,"end_time":"2024-04-26T00:33:16.319406","exception":false,"start_time":"2024-04-26T00:33:16.300427","status":"completed"},"tags":[]},"outputs":[],"source":["def batched_multi_head_attention(\n","    X, M, P_q, P_k, P_v, P_o):\n","    \"\"\"Multi-head Attention on maximum sequence length of queries.\n","    Args:\n","        X: a matrix with shape of [b, n, d]\n","        M: a matrix with shape of [b, m, d]\n","        P_q: a tensor with shape of [b, h, d, k]\n","        P_k: a tensor with shape of [b, h, d, k]\n","        P_v: a tensor with shape of [b, h, d, v]\n","        P_o:  a tensor with shape of [b, h, d, v]\n","    Returns:\n","        y: a tensor with shape of [b, n, d]\n","    \"\"\"\n","    Q = jnp.einsum(\"bnd,bhdk->bhnk\", X, P_q)\n","    K = jnp.einsum(\"bmd,bhdk->bhmk\", M, P_k)\n","    V = jnp.einsum(\"bmd,bhdv->bhmv\", M, P_v)\n","    \n","    logits = jnp.einsum(\"bhnk,bhmk->bhnm\", Q, K)\n","    weights = jax.nn.softmax(logits)\n","    O = jnp.einsum(\"bhnm,bhmv->bhnv\", weights, V)\n","    Y = jnp.einsum(\"bhnv,bhdv->bnd\", O, P_o)\n","    \n","    return Y"]},{"cell_type":"code","execution_count":26,"id":"110073f2","metadata":{"execution":{"iopub.execute_input":"2024-04-26T00:33:16.339514Z","iopub.status.busy":"2024-04-26T00:33:16.338974Z","iopub.status.idle":"2024-04-26T00:33:28.146658Z","shell.execute_reply":"2024-04-26T00:33:28.145532Z"},"papermill":{"duration":11.820163,"end_time":"2024-04-26T00:33:28.148938","exception":false,"start_time":"2024-04-26T00:33:16.328775","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(32, 128, 512)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["X = jax.random.uniform(key, shape=(batch_size, seq_len, d_model)) # Input tensor with seq_len and embedding size \n","M = jax.random.uniform(key, shape=(batch_size, seq_len, d_model)) \n","\n","# Basically this is the dense layer weights, so when input is passed through dense layer we will get an outputs shape (heads, seql_len, head_size) projection\n","P_q = jax.random.uniform(key, shape=(batch_size, seq_len, d_model, d_model // num_heads)) # Projection of input tensor embeddings to each head size which is d_model // num_heads\n","P_k = jax.random.uniform(key, shape=(batch_size, seq_len, d_model, d_model // num_heads))\n","P_v = jax.random.uniform(key, shape=(batch_size, seq_len, d_model, d_model // num_heads))\n","P_o = jax.random.uniform(key, shape=(batch_size, seq_len, d_model, d_model // num_heads))\n","\n","attention_scores = batched_multi_head_attention(X, M, P_q, P_k, P_v, P_o)\n","attention_scores.shape"]},{"cell_type":"markdown","id":"d3027694","metadata":{"papermill":{"duration":0.009083,"end_time":"2024-04-26T00:33:28.167764","exception":false,"start_time":"2024-04-26T00:33:28.158681","status":"completed"},"tags":[]},"source":["# References:\n","\n","1. [Einsum](https://rockt.github.io/2018/04/30/einsum)\n","2. [Attention Is All You Need](https://arxiv.org/pdf/1706.03762)\n","3. [Fast Transformer Decoding: One Write-Head is All\n","You Need](https://arxiv.org/pdf/1911.02150)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":20.947535,"end_time":"2024-04-26T00:33:28.897665","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-26T00:33:07.95013","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}