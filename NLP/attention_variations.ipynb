{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sravanneeli/attention-variations-ipynb?scriptVersionId=174937128\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"79a6954d","metadata":{"papermill":{"duration":0.009299,"end_time":"2024-04-30T18:07:36.979346","exception":false,"start_time":"2024-04-30T18:07:36.970047","status":"completed"},"tags":[]},"source":["# What is Einsum ?\n","\n","* Let's say we want to multiply two matrices `A` and `B` followed by calculating the sum of each column resulting in a vector `C`. Using Einstein summation notation, we can write this as\n","\n","$$c_{j} = \\sum_{i} \\sum_{j} A_{ik}B_{kj} = A_{ik}B_{kj}$$\n"]},{"cell_type":"code","execution_count":1,"id":"d0cf54bf","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-30T18:07:36.999029Z","iopub.status.busy":"2024-04-30T18:07:36.998583Z","iopub.status.idle":"2024-04-30T18:07:39.751461Z","shell.execute_reply":"2024-04-30T18:07:39.750305Z"},"papermill":{"duration":2.766214,"end_time":"2024-04-30T18:07:39.754564","exception":false,"start_time":"2024-04-30T18:07:36.98835","status":"completed"},"tags":[]},"outputs":[],"source":["import jax\n","import numpy as np\n","import jax.numpy as jnp\n","import optax"]},{"cell_type":"code","execution_count":2,"id":"b8c55005","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:39.776281Z","iopub.status.busy":"2024-04-30T18:07:39.775655Z","iopub.status.idle":"2024-04-30T18:07:40.297661Z","shell.execute_reply":"2024-04-30T18:07:40.29623Z"},"papermill":{"duration":0.536281,"end_time":"2024-04-30T18:07:40.300766","exception":false,"start_time":"2024-04-30T18:07:39.764485","status":"completed"},"tags":[]},"outputs":[],"source":["a = jnp.arange(6).reshape((2, 3))"]},{"cell_type":"markdown","id":"2481f5f7","metadata":{"papermill":{"duration":0.010357,"end_time":"2024-04-30T18:07:40.320466","exception":false,"start_time":"2024-04-30T18:07:40.310109","status":"completed"},"tags":[]},"source":["# Transpose"]},{"cell_type":"code","execution_count":3,"id":"f486fd29","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:40.342316Z","iopub.status.busy":"2024-04-30T18:07:40.341846Z","iopub.status.idle":"2024-04-30T18:07:40.384746Z","shell.execute_reply":"2024-04-30T18:07:40.383562Z"},"papermill":{"duration":0.057802,"end_time":"2024-04-30T18:07:40.387558","exception":false,"start_time":"2024-04-30T18:07:40.329756","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([[0, 3],\n","       [1, 4],\n","       [2, 5]], dtype=int32)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["jnp.einsum(\"ij->ji\", a) # basically the notation is saying in abstract way to change each element from i,j position to j,i -> this is what expected in transpose"]},{"cell_type":"markdown","id":"984a8431","metadata":{"papermill":{"duration":0.009211,"end_time":"2024-04-30T18:07:40.407078","exception":false,"start_time":"2024-04-30T18:07:40.397867","status":"completed"},"tags":[]},"source":["# Matrix Sum"]},{"cell_type":"code","execution_count":4,"id":"2af20416","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:40.428241Z","iopub.status.busy":"2024-04-30T18:07:40.427828Z","iopub.status.idle":"2024-04-30T18:07:40.476757Z","shell.execute_reply":"2024-04-30T18:07:40.475678Z"},"papermill":{"duration":0.062201,"end_time":"2024-04-30T18:07:40.479294","exception":false,"start_time":"2024-04-30T18:07:40.417093","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array(15, dtype=int32)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["jnp.einsum(\"ij->\", a) # matrix sum is a single scalar output so there is no notation after `->` which means collapse all columns and rows"]},{"cell_type":"markdown","id":"8e9c31b9","metadata":{"papermill":{"duration":0.008975,"end_time":"2024-04-30T18:07:40.497473","exception":false,"start_time":"2024-04-30T18:07:40.488498","status":"completed"},"tags":[]},"source":["# Column Sum"]},{"cell_type":"code","execution_count":5,"id":"a31eb09d","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:40.518104Z","iopub.status.busy":"2024-04-30T18:07:40.517076Z","iopub.status.idle":"2024-04-30T18:07:40.5477Z","shell.execute_reply":"2024-04-30T18:07:40.546622Z"},"papermill":{"duration":0.043776,"end_time":"2024-04-30T18:07:40.550385","exception":false,"start_time":"2024-04-30T18:07:40.506609","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([3, 5, 7], dtype=int32)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["jnp.einsum(\"ij->j\", a) # matrix sum column wise so the output has only how many dimensions in the column so rows are collapsed."]},{"cell_type":"markdown","id":"3149c3c3","metadata":{"papermill":{"duration":0.009185,"end_time":"2024-04-30T18:07:40.569065","exception":false,"start_time":"2024-04-30T18:07:40.55988","status":"completed"},"tags":[]},"source":["# Row Sum"]},{"cell_type":"code","execution_count":6,"id":"a1f40c21","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:40.590992Z","iopub.status.busy":"2024-04-30T18:07:40.590628Z","iopub.status.idle":"2024-04-30T18:07:40.61896Z","shell.execute_reply":"2024-04-30T18:07:40.61791Z"},"papermill":{"duration":0.04175,"end_time":"2024-04-30T18:07:40.62135","exception":false,"start_time":"2024-04-30T18:07:40.5796","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([ 3, 12], dtype=int32)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["jnp.einsum(\"ij->i\", a)"]},{"cell_type":"markdown","id":"ed4d110f","metadata":{"papermill":{"duration":0.009199,"end_time":"2024-04-30T18:07:40.640068","exception":false,"start_time":"2024-04-30T18:07:40.630869","status":"completed"},"tags":[]},"source":["# Matrix-Vector Multiplication\n","\n","\n"]},{"cell_type":"code","execution_count":7,"id":"9185ec72","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:40.660411Z","iopub.status.busy":"2024-04-30T18:07:40.66001Z","iopub.status.idle":"2024-04-30T18:07:40.712935Z","shell.execute_reply":"2024-04-30T18:07:40.711895Z"},"papermill":{"duration":0.065997,"end_time":"2024-04-30T18:07:40.715334","exception":false,"start_time":"2024-04-30T18:07:40.649337","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([ 5, 14], dtype=int32)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["b = jnp.arange(3) # (3, )\n","jnp.einsum(\"ij,j->i\", a, b) # same as jnp.dot(a, b)"]},{"cell_type":"markdown","id":"d8e34d2f","metadata":{"papermill":{"duration":0.009277,"end_time":"2024-04-30T18:07:40.734368","exception":false,"start_time":"2024-04-30T18:07:40.725091","status":"completed"},"tags":[]},"source":["# Matrix-Matrix Multiplication"]},{"cell_type":"code","execution_count":8,"id":"5e21f987","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:40.754918Z","iopub.status.busy":"2024-04-30T18:07:40.754538Z","iopub.status.idle":"2024-04-30T18:07:40.824627Z","shell.execute_reply":"2024-04-30T18:07:40.82356Z"},"papermill":{"duration":0.083739,"end_time":"2024-04-30T18:07:40.827425","exception":false,"start_time":"2024-04-30T18:07:40.743686","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([[ 25,  28,  31,  34,  37],\n","       [ 70,  82,  94, 106, 118]], dtype=int32)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["a = jnp.arange(6).reshape(2, 3)\n","b = jnp.arange(15).reshape(3, 5)\n","jnp.einsum('ik,kj->ij', a, b)"]},{"cell_type":"code","execution_count":9,"id":"e7f03a73","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:40.850827Z","iopub.status.busy":"2024-04-30T18:07:40.850431Z","iopub.status.idle":"2024-04-30T18:07:40.887359Z","shell.execute_reply":"2024-04-30T18:07:40.886163Z"},"papermill":{"duration":0.05252,"end_time":"2024-04-30T18:07:40.889816","exception":false,"start_time":"2024-04-30T18:07:40.837296","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([ 95, 110, 125, 140, 155], dtype=int32)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["jnp.einsum('ik,kj->j', a, b) # matrix multiplication plus columns wise sum"]},{"cell_type":"code","execution_count":10,"id":"17dad8c2","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:40.911844Z","iopub.status.busy":"2024-04-30T18:07:40.911483Z","iopub.status.idle":"2024-04-30T18:07:40.94784Z","shell.execute_reply":"2024-04-30T18:07:40.946783Z"},"papermill":{"duration":0.050477,"end_time":"2024-04-30T18:07:40.950488","exception":false,"start_time":"2024-04-30T18:07:40.900011","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([155, 470], dtype=int32)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["jnp.einsum('ik,kj->i', a, b) # matrix multiplication plus row wise sum"]},{"cell_type":"markdown","id":"9855dbe8","metadata":{"papermill":{"duration":0.009906,"end_time":"2024-04-30T18:07:40.970161","exception":false,"start_time":"2024-04-30T18:07:40.960255","status":"completed"},"tags":[]},"source":["# Dot Product"]},{"cell_type":"code","execution_count":11,"id":"03dff28b","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:40.992258Z","iopub.status.busy":"2024-04-30T18:07:40.991838Z","iopub.status.idle":"2024-04-30T18:07:41.038268Z","shell.execute_reply":"2024-04-30T18:07:41.03699Z"},"papermill":{"duration":0.06029,"end_time":"2024-04-30T18:07:41.04071","exception":false,"start_time":"2024-04-30T18:07:40.98042","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array(14, dtype=int32)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["a = jnp.arange(3)\n","b = jnp.arange(3,6)\n","jnp.einsum('i,i->', a, b) # notation is basically i is index of a matrix and the i index in b multiplied index wise"]},{"cell_type":"markdown","id":"4adb9151","metadata":{"papermill":{"duration":0.010053,"end_time":"2024-04-30T18:07:41.06074","exception":false,"start_time":"2024-04-30T18:07:41.050687","status":"completed"},"tags":[]},"source":["# Element Wise Multiplication of Two Matrices and the summation"]},{"cell_type":"code","execution_count":12,"id":"58b1c803","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:41.082512Z","iopub.status.busy":"2024-04-30T18:07:41.082113Z","iopub.status.idle":"2024-04-30T18:07:41.127058Z","shell.execute_reply":"2024-04-30T18:07:41.125981Z"},"papermill":{"duration":0.058629,"end_time":"2024-04-30T18:07:41.129435","exception":false,"start_time":"2024-04-30T18:07:41.070806","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([[ 0,  7, 16],\n","       [27, 40, 55]], dtype=int32)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["a = jnp.arange(6).reshape(2, 3)\n","b = jnp.arange(6,12).reshape(2, 3)\n","jnp.einsum('ij,ij->ij', a, b)"]},{"cell_type":"code","execution_count":13,"id":"1cd02b26","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:41.151082Z","iopub.status.busy":"2024-04-30T18:07:41.150736Z","iopub.status.idle":"2024-04-30T18:07:41.179592Z","shell.execute_reply":"2024-04-30T18:07:41.178499Z"},"papermill":{"duration":0.042676,"end_time":"2024-04-30T18:07:41.182174","exception":false,"start_time":"2024-04-30T18:07:41.139498","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array(145, dtype=int32)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["jnp.einsum('ij,ij->', a, b)"]},{"cell_type":"markdown","id":"60c91752","metadata":{"papermill":{"duration":0.010622,"end_time":"2024-04-30T18:07:41.203156","exception":false,"start_time":"2024-04-30T18:07:41.192534","status":"completed"},"tags":[]},"source":["# Outer Product\n","\n","Given two vectors of size $m \\times 1$ and $n \\times 1$respectively\n","\n","$$ u = \\begin{bmatrix}\n","  u_{1} \\\\\n","  u_{2} \\\\\n","  u_{3} \\\\\n","  u_{4} \\\\\n","\\end{bmatrix}\n","\\,\n","v = \\begin{bmatrix}\n","  v_{1} \\\\\n","  v_{2} \\\\\n","  v_{3} \\\\\n","\\end{bmatrix}$$\n","$$$$\n","$$ u \\otimes  v = uv^{T} = \\begin{bmatrix}\n","  u_{1}v_{1} & u_{1}v_{2} & u_{1}v_{3}\\\\\n","  u_{2}v_{1} & u_{2}v_{2} & u_{2}v_{3}\\\\\n","  u_{3}v_{1} & u_{3}v_{2} & u_{3}v_{3}\\\\\n","  u_{4}v_{1} & u_{4}v_{2} & u_{4}v_{3}\\\\\n","\\end{bmatrix}$$"]},{"cell_type":"code","execution_count":14,"id":"eee3fa9a","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:41.227456Z","iopub.status.busy":"2024-04-30T18:07:41.226202Z","iopub.status.idle":"2024-04-30T18:07:41.273455Z","shell.execute_reply":"2024-04-30T18:07:41.272301Z"},"papermill":{"duration":0.062336,"end_time":"2024-04-30T18:07:41.275851","exception":false,"start_time":"2024-04-30T18:07:41.213515","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Array([[ 0,  0,  0,  0],\n","       [ 3,  4,  5,  6],\n","       [ 6,  8, 10, 12]], dtype=int32)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["a = jnp.arange(3)\n","b = jnp.arange(3,7)\n","jnp.einsum('i,j->ij', a, b)"]},{"cell_type":"markdown","id":"21ed8aa1","metadata":{"papermill":{"duration":0.009949,"end_time":"2024-04-30T18:07:41.296148","exception":false,"start_time":"2024-04-30T18:07:41.286199","status":"completed"},"tags":[]},"source":["# Dot-Product Attention\n","\n","$$ \\mbox{Attention}(q, K, V) = \\mbox{Softmax}(\\dfrac {q \\cdot K^{T}}{\\sqrt d_{k}})V$$"]},{"cell_type":"code","execution_count":15,"id":"46c5eda1","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:41.318096Z","iopub.status.busy":"2024-04-30T18:07:41.317735Z","iopub.status.idle":"2024-04-30T18:07:41.323678Z","shell.execute_reply":"2024-04-30T18:07:41.322601Z"},"papermill":{"duration":0.019537,"end_time":"2024-04-30T18:07:41.325953","exception":false,"start_time":"2024-04-30T18:07:41.306416","status":"completed"},"tags":[]},"outputs":[],"source":["def dot_product_attention(q, K, V):\n","    \"\"\" \n","    Dot−Product Attention on one query.\n","    Args :\n","        q : a vector with shape [k]\n","        K: a matrix with shape [m, k]\n","        V: a matrix with shape [m, v]\n","    Returns :\n","        y : a vector with shape [v]\n","    \"\"\"\n","    \n","    logits = jnp.einsum(\"k,mk->m\", q, K)\n","    weights = jax.nn.softmax(logits)\n","    return jnp.einsum(\"m,mv->v\", weights, V)\n","    "]},{"cell_type":"code","execution_count":16,"id":"f49b9bb6","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:41.34789Z","iopub.status.busy":"2024-04-30T18:07:41.34751Z","iopub.status.idle":"2024-04-30T18:07:41.391298Z","shell.execute_reply":"2024-04-30T18:07:41.390161Z"},"papermill":{"duration":0.057662,"end_time":"2024-04-30T18:07:41.39392","exception":false,"start_time":"2024-04-30T18:07:41.336258","status":"completed"},"tags":[]},"outputs":[],"source":["key = jax.random.PRNGKey(13)\n","d_model = 512\n","seq_len = 128\n","num_heads = 8\n","batch_size = 32"]},{"cell_type":"code","execution_count":17,"id":"d4f8fc55","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:41.416317Z","iopub.status.busy":"2024-04-30T18:07:41.415937Z","iopub.status.idle":"2024-04-30T18:07:41.422024Z","shell.execute_reply":"2024-04-30T18:07:41.420916Z"},"papermill":{"duration":0.019942,"end_time":"2024-04-30T18:07:41.424271","exception":false,"start_time":"2024-04-30T18:07:41.404329","status":"completed"},"tags":[]},"outputs":[],"source":["q = np.random.randn(d_model // num_heads,) # One token with embedding size of 384 projected to a 64 one of head\n","K = np.random.randn(seq_len, d_model // num_heads) # consider a sentence with max of 128 sequence length and each token with 384 dimension projected to a 64 one of head\n","V = np.random.randn(seq_len, d_model // num_heads) # consider a sentence with max of 128 sequence length and each token with 384 dimension projected to a 64 one of head"]},{"cell_type":"code","execution_count":18,"id":"3b16d982","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:41.447067Z","iopub.status.busy":"2024-04-30T18:07:41.446721Z","iopub.status.idle":"2024-04-30T18:07:41.452318Z","shell.execute_reply":"2024-04-30T18:07:41.451198Z"},"papermill":{"duration":0.020516,"end_time":"2024-04-30T18:07:41.455174","exception":false,"start_time":"2024-04-30T18:07:41.434658","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["q: (64,)\n","K: (128, 64)\n","V: (128, 64)\n"]}],"source":["print(f\"q: {q.shape}\")\n","print(f\"K: {K.shape}\")\n","print(f\"V: {V.shape}\")"]},{"cell_type":"code","execution_count":19,"id":"b5a4294a","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:41.47803Z","iopub.status.busy":"2024-04-30T18:07:41.477678Z","iopub.status.idle":"2024-04-30T18:07:41.660818Z","shell.execute_reply":"2024-04-30T18:07:41.659748Z"},"papermill":{"duration":0.197305,"end_time":"2024-04-30T18:07:41.663075","exception":false,"start_time":"2024-04-30T18:07:41.46577","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(64,)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["attention_scores = dot_product_attention(q, K, V)\n","attention_scores.shape"]},{"cell_type":"markdown","id":"c75ba932","metadata":{"papermill":{"duration":0.01048,"end_time":"2024-04-30T18:07:41.742562","exception":false,"start_time":"2024-04-30T18:07:41.732082","status":"completed"},"tags":[]},"source":["# Scaled Dot-Product Attention\n","\n","$$ Attention(Q, K, V) = softmax(\\dfrac {Q \\cdot K^{T}}{\\sqrt d_{k}})V$$"]},{"cell_type":"code","execution_count":20,"id":"09b46df5","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:41.765802Z","iopub.status.busy":"2024-04-30T18:07:41.765095Z","iopub.status.idle":"2024-04-30T18:07:41.770764Z","shell.execute_reply":"2024-04-30T18:07:41.769781Z"},"papermill":{"duration":0.019806,"end_time":"2024-04-30T18:07:41.77307","exception":false,"start_time":"2024-04-30T18:07:41.753264","status":"completed"},"tags":[]},"outputs":[],"source":["def scaled_dot_product_attention(Q, K, V, mask):\n","    \"\"\" \n","    Scaled Dot−Product Attention on maximum sequence length of queries.\n","    Args :\n","        Q: a matrix with shape [n, head_size]\n","        K: a matrix with shape [m, head_size]\n","        V: a matrix with shape [m, head_size]\n","    Returns :\n","        y : a vector with shape [m, v]\n","    \"\"\"\n","    \n","    logits = jnp.einsum(\"nd,md->nm\", Q, K)\n","    weights = jax.nn.softmax(logits + mask)\n","    return jnp.einsum(\"nm,mv->nv\", weights, V)\n","    "]},{"cell_type":"code","execution_count":21,"id":"33b4ddb9","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:41.795986Z","iopub.status.busy":"2024-04-30T18:07:41.795609Z","iopub.status.idle":"2024-04-30T18:07:41.802941Z","shell.execute_reply":"2024-04-30T18:07:41.802006Z"},"papermill":{"duration":0.02173,"end_time":"2024-04-30T18:07:41.805355","exception":false,"start_time":"2024-04-30T18:07:41.783625","status":"completed"},"tags":[]},"outputs":[],"source":["Q = 0.02 *  np.random.randn(seq_len, d_model // num_heads) # consider a sentence with max of 128 sequence length and each token with 384 dimension projected to a 64 one of head\n","K = 0.02 *  np.random.randn(seq_len, d_model // num_heads) # consider a sentence with max of 128 sequence length and each token with 384 dimension projected to a 64 one of head\n","V = 0.02 *  np.random.randn(seq_len, d_model // num_heads) # consider a sentence with max of 128 sequence length and each token with 384 dimension projected to a 64 one of head\n","\n","\n","mask = np.tril(np.ones((Q.shape[0], K.shape[0])))\n","mask = np.where(mask == 0, -np.inf, 0)"]},{"cell_type":"code","execution_count":22,"id":"76068c59","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:41.828635Z","iopub.status.busy":"2024-04-30T18:07:41.828264Z","iopub.status.idle":"2024-04-30T18:07:42.0855Z","shell.execute_reply":"2024-04-30T18:07:42.084011Z"},"papermill":{"duration":0.271726,"end_time":"2024-04-30T18:07:42.087846","exception":false,"start_time":"2024-04-30T18:07:41.81612","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(128, 64)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["attention_scores = scaled_dot_product_attention(Q, K, V, mask)\n","attention_scores.shape"]},{"cell_type":"markdown","id":"b3382512","metadata":{"papermill":{"duration":0.010777,"end_time":"2024-04-30T18:07:42.109621","exception":false,"start_time":"2024-04-30T18:07:42.098844","status":"completed"},"tags":[]},"source":["# Multi Head Attention"]},{"cell_type":"code","execution_count":23,"id":"66718117","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:42.132685Z","iopub.status.busy":"2024-04-30T18:07:42.132309Z","iopub.status.idle":"2024-04-30T18:07:42.139388Z","shell.execute_reply":"2024-04-30T18:07:42.138304Z"},"papermill":{"duration":0.021419,"end_time":"2024-04-30T18:07:42.141712","exception":false,"start_time":"2024-04-30T18:07:42.120293","status":"completed"},"tags":[]},"outputs":[],"source":["def multi_head_attention(\n","    X, M, P_q, P_k, P_v, P_o, mask):\n","    \"\"\"Multi-head Attention on maximum sequence length of queries.\n","    Args:\n","        X: a matrix with shape of [n, d]\n","        M: a matrix with shape of [m, d]\n","        P_q: a tensor with shape of [h, d, k]\n","        P_k: a tensor with shape of [h, d, k]\n","        P_v: a tensor with shape of [h, d, v]\n","        P_o:  a tensor with shape of [h, d, v]\n","        mask: a tensor with shape of [h, n, m]\n","    Returns:\n","        y: a tensor with shape of [n, d]\n","    \"\"\"\n","    Q = jnp.einsum(\"nd,hdk->hnk\", X, P_q)\n","    K = jnp.einsum(\"md,hdk->hmk\", M, P_k)\n","    V = jnp.einsum(\"md,hdv->hmv\", M, P_v)\n","    \n","    logits = jnp.einsum(\"hnk,hmk->hnm\", Q, K)\n","    weights = jax.nn.softmax(logits + mask, axis=-1)\n","    O = jnp.einsum(\"hnm,hmv->hnv\", weights, V)\n","    Y = jnp.einsum(\"hnv,hdv->nd\", O, P_o)\n","    \n","    return Y"]},{"cell_type":"code","execution_count":24,"id":"6c8a3822","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:42.165009Z","iopub.status.busy":"2024-04-30T18:07:42.1646Z","iopub.status.idle":"2024-04-30T18:07:42.635565Z","shell.execute_reply":"2024-04-30T18:07:42.634296Z"},"papermill":{"duration":0.485925,"end_time":"2024-04-30T18:07:42.638372","exception":false,"start_time":"2024-04-30T18:07:42.152447","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(128, 512)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["X = np.random.uniform(size=(seq_len, d_model)) # Input tensor with seq_len and embedding size \n","M = np.random.uniform(size=(seq_len, d_model))\n","\n","# Basically this is the dense layer weights, so when input is passed through dense layer we will get an outputs shape (heads, seql_len, head_size) projection\n","P_q = 0.02 * np.random.randn(num_heads, d_model, d_model // num_heads) # Projection of input tensor embeddings to each head size which is d_model // num_heads\n","P_k = 0.02 * np.random.randn(num_heads, d_model, d_model // num_heads)\n","P_v = 0.02 * np.random.randn(num_heads, d_model, d_model // num_heads)\n","P_o = 0.02 * np.random.randn(num_heads, d_model, d_model // num_heads)\n","\n","mask = np.tril(np.ones((num_heads, X.shape[0], M.shape[0])))\n","mask = np.where(mask == 0, -np.inf, 0)\n","\n","attention_scores = multi_head_attention(X, M, P_q, P_k, P_v, P_o, mask)\n","attention_scores.shape"]},{"cell_type":"markdown","id":"96fb6921","metadata":{"papermill":{"duration":0.010845,"end_time":"2024-04-30T18:07:42.660513","exception":false,"start_time":"2024-04-30T18:07:42.649668","status":"completed"},"tags":[]},"source":["# Batched Multi Head Attention"]},{"cell_type":"code","execution_count":25,"id":"8dc02754","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:42.683866Z","iopub.status.busy":"2024-04-30T18:07:42.683471Z","iopub.status.idle":"2024-04-30T18:07:42.690852Z","shell.execute_reply":"2024-04-30T18:07:42.689713Z"},"papermill":{"duration":0.021954,"end_time":"2024-04-30T18:07:42.693364","exception":false,"start_time":"2024-04-30T18:07:42.67141","status":"completed"},"tags":[]},"outputs":[],"source":["def batched_multi_head_attention(\n","    X, M, P_q, P_k, P_v, P_o):\n","    \"\"\"Multi-head Attention on maximum sequence length of queries.\n","    Args:\n","        X: a matrix with shape of [b, n, d]\n","        M: a matrix with shape of [b, m, d]\n","        P_q: a tensor with shape of [b, h, d, k]\n","        P_k: a tensor with shape of [b, h, d, k]\n","        P_v: a tensor with shape of [b, h, d, v]\n","        P_o:  a tensor with shape of [b, h, d, v]\n","    Returns:\n","        y: a tensor with shape of [b, n, d]\n","    \"\"\"\n","    Q = jnp.einsum(\"bnd,bhdk->bhnk\", X, P_q)\n","    K = jnp.einsum(\"bmd,bhdk->bhmk\", M, P_k)\n","    V = jnp.einsum(\"bmd,bhdv->bhmv\", M, P_v)\n","    \n","    logits = jnp.einsum(\"bhnk,bhmk->bhnm\", Q, K)\n","    weights = jax.nn.softmax(logits)\n","    O = jnp.einsum(\"bhnm,bhmv->bhnv\", weights, V)\n","    Y = jnp.einsum(\"bhnv,bhdv->bnd\", O, P_o)\n","    \n","    return Y"]},{"cell_type":"code","execution_count":26,"id":"0252043a","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:42.716866Z","iopub.status.busy":"2024-04-30T18:07:42.716505Z","iopub.status.idle":"2024-04-30T18:07:44.872916Z","shell.execute_reply":"2024-04-30T18:07:44.871736Z"},"papermill":{"duration":2.171437,"end_time":"2024-04-30T18:07:44.87568","exception":false,"start_time":"2024-04-30T18:07:42.704243","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(32, 128, 512)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["X = np.random.uniform(size=(batch_size, seq_len, d_model)) # Input tensor with seq_len and embedding size \n","M = np.random.uniform(size=(batch_size, seq_len, d_model))\n","\n","# Basically this is the dense layer weights, so when input is passed through dense layer we will get an outputs shape (heads, seql_len, head_size) projection\n","P_q = 0.02 * np.random.randn(batch_size, num_heads, d_model, d_model // num_heads) # Projection of input tensor embeddings to each head size which is d_model // num_heads\n","P_k = 0.02 * np.random.randn(batch_size, num_heads, d_model, d_model // num_heads)\n","P_v = 0.02 * np.random.randn(batch_size, num_heads, d_model, d_model // num_heads)\n","P_o = 0.02 * np.random.randn(batch_size, num_heads, d_model, d_model // num_heads)\n","\n","attention_scores = batched_multi_head_attention(X, M, P_q, P_k, P_v, P_o)\n","attention_scores.shape"]},{"cell_type":"markdown","id":"43f5fcff","metadata":{"papermill":{"duration":0.010801,"end_time":"2024-04-30T18:07:44.901251","exception":false,"start_time":"2024-04-30T18:07:44.89045","status":"completed"},"tags":[]},"source":["# Batched Decoder Multi Head Attention (Masking Included if it's decoder)"]},{"cell_type":"code","execution_count":27,"id":"1024ec98","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:44.925703Z","iopub.status.busy":"2024-04-30T18:07:44.925237Z","iopub.status.idle":"2024-04-30T18:07:44.93424Z","shell.execute_reply":"2024-04-30T18:07:44.933066Z"},"papermill":{"duration":0.02392,"end_time":"2024-04-30T18:07:44.936568","exception":false,"start_time":"2024-04-30T18:07:44.912648","status":"completed"},"tags":[]},"outputs":[],"source":["def batched_multi_head_attention_masked(\n","    X, M, mask, P_q, P_k, P_v, P_o):\n","    \"\"\"Multi-head Attention on maximum sequence length of queries.\n","    Args:\n","        X: a matrix with shape of [b, n, d]\n","        M: a matrix with shape of [b, m, d]\n","        P_q: a tensor with shape of [b, h, d, k]\n","        P_k: a tensor with shape of [b, h, d, k]\n","        P_v: a tensor with shape of [b, h, d, v]\n","        P_o:  a tensor with shape of [b, h, d, v]\n","    Returns:\n","        y: a tensor with shape of [b, n, d]\n","    \"\"\"\n","    Q = jnp.einsum(\"bnd,bhdk->bhnk\", X, P_q)\n","    K = jnp.einsum(\"bmd,bhdk->bhmk\", M, P_k)\n","    V = jnp.einsum(\"bmd,bhdv->bhmv\", M, P_v)\n","    \n","    logits = jnp.einsum(\"bhnk,bhmk->bhnm\", Q, K)\n","    weights = jax.nn.softmax(logits + mask, axis=-1)\n","    O = jnp.einsum(\"bhnm,bhmv->bhnv\", weights, V)\n","    Y = jnp.einsum(\"bhnv,bhdv->bnd\", O, P_o)\n","    \n","    return Y"]},{"cell_type":"code","execution_count":28,"id":"079e4db1","metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:07:44.961083Z","iopub.status.busy":"2024-04-30T18:07:44.960106Z","iopub.status.idle":"2024-04-30T18:07:46.41956Z","shell.execute_reply":"2024-04-30T18:07:46.418289Z"},"papermill":{"duration":1.47411,"end_time":"2024-04-30T18:07:46.421858","exception":false,"start_time":"2024-04-30T18:07:44.947748","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(32, 128, 512)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["X = np.random.uniform(size=(batch_size, seq_len, d_model)) # Input tensor with seq_len and embedding size \n","M = np.random.uniform(size=(batch_size, seq_len, d_model))\n","mask = np.tril(np.ones((batch_size, num_heads, X.shape[1], M.shape[1])))\n","mask = np.where(mask == 0, -np.inf, 0)\n","\n","                \n","# Basically this is the dense layer weights, so when input is passed through dense layer we will get an outputs shape (heads, seql_len, head_size) projection\n","P_q = 0.02 * np.random.randn(batch_size, num_heads, d_model, d_model // num_heads) # Projection of input tensor embeddings to each head size which is d_model // num_heads\n","P_k = 0.02 * np.random.randn(batch_size, num_heads, d_model, d_model // num_heads)\n","P_v = 0.02 * np.random.randn(batch_size, num_heads, d_model, d_model // num_heads)\n","P_o = 0.02 * np.random.randn(batch_size, num_heads, d_model, d_model // num_heads)\n","\n","attention_scores = batched_multi_head_attention_masked(X, M, mask, P_q, P_k, P_v, P_o)\n","attention_scores.shape"]},{"cell_type":"markdown","id":"605dccc6","metadata":{"papermill":{"duration":0.010693,"end_time":"2024-04-30T18:07:46.443813","exception":false,"start_time":"2024-04-30T18:07:46.43312","status":"completed"},"tags":[]},"source":["# References:\n","\n","1. [Einsum](https://rockt.github.io/2018/04/30/einsum)\n","2. [Attention Is All You Need](https://arxiv.org/pdf/1706.03762)\n","3. [Fast Transformer Decoding: One Write-Head is All\n","You Need](https://arxiv.org/pdf/1911.02150)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":13.007215,"end_time":"2024-04-30T18:07:47.176544","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-30T18:07:34.169329","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}